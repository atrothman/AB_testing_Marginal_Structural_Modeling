{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## import libraries ##\n",
    "######################\n",
    "import numpy as np\n",
    "np.random.seed(1081565)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(n=2000000, A_on_Y=0):\n",
    "\n",
    "    ## Z: “randomized” binary intervention assignment (0, 1)    \n",
    "    ## A: observed binary intervention (0, 1)\n",
    "    ## L: direct binary determinant of intervention A (0, 1)\n",
    "    ## U1: binary unmeasured common cause of A and Y\n",
    "    ## U2: binary unmeasured common cause of L and Y\n",
    "    ## C: censoring variable\n",
    "    ## Y: countinuous outcome\n",
    "    \n",
    "    ## specify dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    ## specify variables Z, U1, and U2\n",
    "    Z_split = 0.4\n",
    "    U1_split = 0.52\n",
    "    U2_split = 0.23\n",
    "    df['Z'] = np.random.choice([0, 1], size=n, replace=True, p=[Z_split, (1-Z_split)])\n",
    "    df['U1'] = np.random.choice([0, 1], size=n, replace=True, p=[U1_split, (1-U1_split)])\n",
    "    df['U2'] = np.random.choice([0, 1], size=n, replace=True, p=[U2_split, (1-U2_split)])\n",
    "    \n",
    "    ## specify variable A\n",
    "    lambda_0 = -5.2\n",
    "    lambda_1 = 9.3\n",
    "    lambda_2 = 3.45   \n",
    "    df['A'] = 0\n",
    "    df.loc[(df['Z']==0) & (df['U1']==0), 'A'] = np.random.binomial(1, (1/(1+np.exp(-lambda_0))), size=df.loc[(df['Z']==0) & (df['U1']==0), 'A'].shape[0])\n",
    "    df.loc[(df['Z']==1) & (df['U1']==0), 'A'] = np.random.binomial(1, (1/(1+np.exp(-(lambda_0+lambda_1)))), size=df.loc[(df['Z']==1) & (df['U1']==0), 'A'].shape[0])\n",
    "    df.loc[(df['Z']==0) & (df['U1']==1), 'A'] = np.random.binomial(1, (1/(1+np.exp(-(lambda_0+lambda_2)))), size=df.loc[(df['Z']==0) & (df['U1']==1), 'A'].shape[0])\n",
    "    df.loc[(df['Z']==1) & (df['U1']==1), 'A'] = np.random.binomial(1, (1/(1+np.exp(-(lambda_0+lambda_1+lambda_2)))), size=df.loc[(df['Z']==1) & (df['U1']==1), 'A'].shape[0])\n",
    "    #model = smf.glm('A ~ Z + U1', data=df, family=sm.families.Binomial()).fit()\n",
    "    #print(model.summary())\n",
    "    #pd.crosstab(df['Z'], df['A'])\n",
    "    #pd.crosstab(df['Z'], df['A'], normalize=True)\n",
    "           \n",
    "    ## specify variable L\n",
    "    Beta_0 = -0.52\n",
    "    Beta_1 = 2.32\n",
    "    Beta_2 = 1.98\n",
    "    df['L'] = 0\n",
    "    df.loc[(df['A']==0) & (df['U2']==0), 'L'] = np.random.binomial(1, (1/(1+np.exp(-Beta_0))), size=df.loc[(df['A']==0) & (df['U2']==0), 'L'].shape[0])\n",
    "    df.loc[(df['A']==1) & (df['U2']==0), 'L'] = np.random.binomial(1, (1/(1+np.exp(-(Beta_0+Beta_1)))), size=df.loc[(df['A']==1) & (df['U2']==0), 'L'].shape[0])\n",
    "    df.loc[(df['A']==0) & (df['U2']==1), 'L'] = np.random.binomial(1, (1/(1+np.exp(-(Beta_0+Beta_2)))), size=df.loc[(df['A']==0) & (df['U2']==1), 'L'].shape[0])\n",
    "    df.loc[(df['A']==1) & (df['U2']==1), 'L'] = np.random.binomial(1, (1/(1+np.exp(-(Beta_0+Beta_1+Beta_2)))), size=df.loc[(df['A']==1) & (df['U2']==1), 'L'].shape[0])\n",
    "    #model = smf.glm('L ~ A + U2', data=df, family=sm.families.Binomial()).fit()\n",
    "    #print(model.summary())\n",
    "    \n",
    "    ## specify variable C\n",
    "    psi_0 = 0.15\n",
    "    psi_1 = -5.8\n",
    "    df['C'] = 0\n",
    "    df.loc[df['L']==0, 'C'] = np.random.binomial(1, (1/(1+np.exp(-psi_0))), size=df.loc[df['L']==0, 'C'].shape[0])\n",
    "    df.loc[df['L']==1, 'C'] = np.random.binomial(1, (1/(1+np.exp(-(psi_0+psi_1)))), size=df.loc[df['L']==1, 'C'].shape[0])\n",
    "    #model = smf.glm('C ~ L', data=df, family=sm.families.Binomial()).fit()\n",
    "    #print(model.summary())\n",
    "    \n",
    "    ## specify variable Y\n",
    "    theta_0 = -0.5\n",
    "    theta_1 = 5.78\n",
    "    theta_2 = A_on_Y\n",
    "    theta_3 = 1.42\n",
    "    df['Y'] = theta_0 + (theta_1*df['U2']) + (theta_2*df['A']) + (theta_3*df['U1']) + np.random.normal(0, 0.5, df.shape[0])\n",
    "    \n",
    "    df_observed = df[['Z', 'A', 'L', 'C', 'Y']].copy()\n",
    "    df_observed.loc[df['C']==1, 'Y'] = None\n",
    "    \n",
    "    return(df, df_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "## simulate dataset with no causal effect difference of A on Y ##\n",
    "#################################################################\n",
    "df, df_observed = simulate_dataset(n=2000000, A_on_Y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Z  U1  U2  A  L  C         Y\n",
      "0  0   0   1  0  1  0  4.957074\n",
      "1  1   0   1  1  1  0  5.717914\n",
      "2  1   1   0  1  1  0  0.795860\n",
      "3  0   1   1  0  0  1  6.636585\n",
      "4  0   0   1  0  1  0  5.645637\n",
      "5  0   1   1  0  1  0  7.528026\n",
      "6  0   0   0  0  1  0 -0.839650\n",
      "7  1   1   1  1  1  0  6.888819\n",
      "8  1   0   0  1  1  0 -0.576333\n",
      "9  1   0   0  1  0  1 -0.747018\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## the \"true\" data ##\n",
    "#####################\n",
    "print(df.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Z  A  L  C         Y\n",
      "0  0  0  1  0  4.957074\n",
      "1  1  1  1  0  5.717914\n",
      "2  1  1  1  0  0.795860\n",
      "3  0  0  0  1       NaN\n",
      "4  0  0  1  0  5.645637\n",
      "5  0  0  1  0  7.528026\n",
      "6  0  0  1  0 -0.839650\n",
      "7  1  1  1  0  6.888819\n",
      "8  1  1  1  0 -0.576333\n",
      "9  1  1  0  1       NaN\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "## data we get to \"observe\" in our analysis ##\n",
    "##############################################\n",
    "print(df_observed.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.922117\n",
      "1    0.077883\n",
      "Name: C, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "## print percentage of censored observations (c=1) ##\n",
    "#####################################################\n",
    "print(df_observed['C'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IPWs(df):\n",
    "    \n",
    "    PS_model = smf.glm('C ~ L', data=df, family=sm.families.Binomial()).fit()\n",
    "    df['PS'] = PS_model.predict(df)\n",
    "    df['IPW'] = 0\n",
    "    df.loc[df['C']==1, 'IPW'] = 0\n",
    "    df.loc[df['C']==0, 'IPW'] = 1 / (1 - df.loc[df['C']==0, 'PS'])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## get Inverse Probability Weights for Marginal Structural Modeling ##\n",
    "######################################################################\n",
    "df_observed = get_IPWs(df_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     2874.\n",
      "Date:                Sun, 20 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        17:13:13   Log-Likelihood:            -4.2980e+06\n",
      "No. Observations:             1844234   AIC:                         8.596e+06\n",
      "Df Residuals:                 1844232   BIC:                         8.596e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.9047      0.003   1627.123      0.000       4.899       4.911\n",
      "Z             -0.2035      0.004    -53.609      0.000      -0.211      -0.196\n",
      "==============================================================================\n",
      "Omnibus:                   282935.881   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           439110.858\n",
      "Skew:                          -1.195   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.081   Cond. No.                         3.05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "## ITT estimator of Z on Y (not adjusting for informative censoring) ##\n",
    "#######################################################################\n",
    "model = smf.ols(formula='Y ~ Z', data=df_observed).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.000\n",
      "Model:                            WLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                   0.06952\n",
      "Date:                Sun, 20 Dec 2020   Prob (F-statistic):              0.792\n",
      "Time:                        17:13:28   Log-Likelihood:            -4.3891e+06\n",
      "No. Observations:             1844234   AIC:                         8.778e+06\n",
      "Df Residuals:                 1844232   BIC:                         8.778e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.6310      0.003   1539.692      0.000       4.625       4.637\n",
      "Z              0.0010      0.004      0.264      0.792      -0.007       0.009\n",
      "==============================================================================\n",
      "Omnibus:                   337436.887   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           555256.881\n",
      "Skew:                          -1.313   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.575   Cond. No.                         2.92\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "## ITT estimator of Z on Y, adjusting for informative censoring with MSM ##\n",
    "###########################################################################\n",
    "MSM_model = smf.wls('Y ~ Z', data=df_observed, weights=np.array(df_observed['IPW'], dtype=np.float64)).fit()\n",
    "print(MSM_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## simulate dataset with causal effect difference of A on Y of 0.12 ##\n",
    "######################################################################\n",
    "df, df_observed = simulate_dataset(n=2000000, A_on_Y=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "## get Inverse Probability Weights for Marginal Structural Modeling ##\n",
    "######################################################################\n",
    "df_observed = get_IPWs(df_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     717.5\n",
      "Date:                Sun, 20 Dec 2020   Prob (F-statistic):          5.14e-158\n",
      "Time:                        17:29:23   Log-Likelihood:            -4.2974e+06\n",
      "No. Observations:             1844024   AIC:                         8.595e+06\n",
      "Df Residuals:                 1844022   BIC:                         8.595e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.9165      0.003   1629.903      0.000       4.911       4.922\n",
      "Z             -0.1017      0.004    -26.785      0.000      -0.109      -0.094\n",
      "==============================================================================\n",
      "Omnibus:                   282701.117   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           438581.143\n",
      "Skew:                          -1.194   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.084   Cond. No.                         3.05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## ITT estimator of Z on Y ##\n",
    "#############################\n",
    "model = smf.ols(formula='Y ~ Z', data=df_observed).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.000\n",
      "Model:                            WLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     713.3\n",
      "Date:                Sun, 20 Dec 2020   Prob (F-statistic):          4.05e-157\n",
      "Time:                        17:29:28   Log-Likelihood:            -4.3887e+06\n",
      "No. Observations:             1844024   AIC:                         8.777e+06\n",
      "Df Residuals:                 1844022   BIC:                         8.778e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.6413      0.003   1542.100      0.000       4.635       4.647\n",
      "Z              0.1037      0.004     26.708      0.000       0.096       0.111\n",
      "==============================================================================\n",
      "Omnibus:                   338156.650   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           556889.779\n",
      "Skew:                          -1.314   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.584   Cond. No.                         2.93\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "## ITT estimator of Z on Y, adjusting for informative censoring with MSM ##\n",
    "###########################################################################\n",
    "MSM_model = smf.wls('Y ~ Z', data=df_observed, weights=np.array(df_observed['IPW'], dtype=np.float64)).fit()\n",
    "print(MSM_model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
